{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhmeaWpsRb8W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('/content/subset.csv')\n",
        "\n",
        "# Convert 'true' to 1 and 'false' to 0 in the 'label' column\n",
        "df['label'] = df['label'].replace({'true': 1, 'false': 0})\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "df.to_csv('path_to_your_modified_file.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "uhNQmJy7R4uV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import XLNetTokenizer\n",
        "\n",
        "# Load the combined dataset\n",
        "df = pd.read_csv('/content/subset.csv')\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.5, random_state=42, stratify=df['label'])\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "# Ensure all text entries are strings\n",
        "train_texts = train_df['text'].astype(str).tolist()\n",
        "test_texts = test_df['text'].astype(str).tolist()\n",
        "train_labels = train_df['label'].tolist()\n",
        "test_labels = test_df['label'].tolist()\n",
        "\n",
        "# Tokenize the text\n",
        "def tokenize_texts(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "train_encodings = tokenize_texts(train_texts)\n",
        "test_encodings = tokenize_texts(test_texts)"
      ],
      "metadata": {
        "id": "SoTQxW2zSgQU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import XLNetForSequenceClassification\n",
        "\n",
        "# Load the model\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3mnLKjOSkhn",
        "outputId": "3106a107-82d4-4f38-aa5d-adb2d50d005a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (activation_function): GELUActivation()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import XLNetForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Assuming 'train_labels' and 'test_labels' are lists of 'true'/'false' strings\n",
        "# Here, you need to define or import 'train_labels' and 'test_labels'\n",
        "train_labels = [1 if label == 'true' else 0 for label in train_labels]\n",
        "test_labels = [1 if label == 'true' else 0 for label in test_labels]\n",
        "\n",
        "# Convert labels to tensors\n",
        "train_labels = torch.tensor(train_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Assuming 'train_encodings' and 'test_encodings' are dicts with 'input_ids' and 'attention_mask'\n",
        "# Here, you need to define or import 'train_encodings' and 'test_encodings'\n",
        "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
        "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Initialize the XLNet model for sequence classification\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer and Scheduler\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_loader) * 4  # Assuming 4 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training function\n",
        "# Training function\n",
        "def train(model, train_loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
        "        model.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)  # Fixed the typo here\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    return accuracy, f1\n",
        "\n",
        "# Training and Evaluation\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {train_loss}\")\n",
        "\n",
        "accuracy, f1 = evaluate(model, test_loader)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mBbXoGhO9Di",
        "outputId": "6f58bcbd-279a-4ebf-8355-e6387af757c4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.02302498549374471\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ]
    }
  ]
}